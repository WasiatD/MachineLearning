{
  "cells": [
    {
      "metadata": {
        "id": "abhnpVkeM_qC"
      },
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ]
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "2KOF-lZtM_qD"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Layer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Path ke direktori yang akan dihapus\n",
        "directory_to_delete = '/kaggle/input/plantdisease/PlantVillage'\n",
        "# List folder yang ada di dalam direktori\n",
        "folders = ['Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy']\n",
        "\n",
        "# Iterasi melalui setiap folder dan hapus\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join(directory_to_delete, folder)\n",
        "    if os.path.exists(folder_path):\n",
        "        shutil.rmtree(folder_path)\n",
        "        print(f\"Folder {folder_path} berhasil dihapus.\")\n",
        "    else:\n",
        "        print(f\"Folder {folder_path} tidak ditemukan.\")\n",
        "\n",
        "print(\"Proses penghapusan selesai.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9_YhrAC0Gy0",
        "outputId": "ee4d65d1-7e77-4bf4-83e0-9fd56c1e2933"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder /kaggle/input/plantdisease/PlantVillage/Potato___Early_blight tidak ditemukan.\n",
            "Folder /kaggle/input/plantdisease/PlantVillage/Potato___Late_blight tidak ditemukan.\n",
            "Folder /kaggle/input/plantdisease/PlantVillage/Potato___healthy tidak ditemukan.\n",
            "Proses penghapusan selesai.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "jzE9kaX3M_qE"
      },
      "cell_type": "code",
      "source": [
        "disease_types = ['Pepper__bell___Bacterial_spot','Pepper__bell___healthy',\n",
        "                 'Tomato_Bacterial_spot','Tomato_Early_blight','Tomato_Late_blight','Tomato_Leaf_Mold',\n",
        "                 'Tomato_Septoria_leaf_spot','Tomato_Spider_mites_Two_spotted_spider_mite','Tomato__Target_Spot',\n",
        "                 'Tomato__Tomato_YellowLeaf__Curl_Virus','Tomato__Tomato_mosaic_virus','Tomato_healthy'\n",
        "                ]\n",
        "\n",
        "data_dir = '../input/plantdisease/PlantVillage/'\n",
        "train_dir = os.path.join(data_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "zRFjOJCZM_qE",
        "outputId": "f579b477-c374-47a3-dbca-90ffd3542355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "cell_type": "code",
      "source": [
        "train_data = []\n",
        "for diseases, sp in enumerate(disease_types):\n",
        "    for file in os.listdir(os.path.join(train_dir, sp)):\n",
        "        train_data.append(['{}/{}'.format(sp, file), diseases, sp])\n",
        "\n",
        "train = pd.DataFrame(train_data, columns=['File', 'DiseaseID','Disease Type'])\n",
        "train.head(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../input/plantdisease/PlantVillage/Pepper__bell___Bacterial_spot'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-ea78ee8e2e2c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdiseases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisease_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiseases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/plantdisease/PlantVillage/Pepper__bell___Bacterial_spot'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_kelas = train[['DiseaseID', 'Disease Type']].drop_duplicates()\n",
        "\n",
        "# Urutkan DataFrame list_kelas berdasarkan DiseaseID\n",
        "list_kelas = list_kelas.sort_values(by='DiseaseID').reset_index(drop=True)\n",
        "\n",
        "# Tampilkan list_kelas\n",
        "list_kelas.head(12)"
      ],
      "metadata": {
        "id": "DwWh1TqFt-Ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AuV17L1cM_qE"
      },
      "cell_type": "markdown",
      "source": [
        "# Randomizing the Training Sample"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "UtSp8Wk7M_qE"
      },
      "cell_type": "code",
      "source": [
        "seed = 45\n",
        "train = train.sample(frac=1, random_state = seed)\n",
        "train_index = np.arange(len(train)) #to reset the indices\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9plHbmCiM_qE"
      },
      "cell_type": "markdown",
      "source": [
        "**Let's create Helper functions for visualizing diseases**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ZqfPt0glM_qE"
      },
      "cell_type": "code",
      "source": [
        "def disease_type(disease_type, rows, cols):\n",
        "    fig,ax = plt.subplots(rows, cols, figsize=(12,12))\n",
        "    disease_type = train['File'][train['Disease Type'] == disease_type].values\n",
        "    n = 0\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            image_path = os.path.join(data_dir, disease_type[n])\n",
        "            ax[i, j].set_xticks([])\n",
        "            ax[i, j].set_yticks([])\n",
        "            ax[i, j].imshow(cv2.imread(image_path))\n",
        "            n += 1\n",
        "# Displays first n images of class from training set\n",
        "disease_type('Tomato_Bacterial_spot', 5, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vkZIPfkUM_qF"
      },
      "cell_type": "markdown",
      "source": [
        "**Let's look at some healthy samples**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "H-6-YVhKM_qF"
      },
      "cell_type": "code",
      "source": [
        "disease_type('Tomato_healthy', 5, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "module_selection = (\"inception_v3\", 299, 2048) #@param [\"(\\\"mobilenet_v2\\\", 224, 1280)\", \"(\\\"inception_v3\\\", 299, 2048)\"] {type:\"raw\", allow-input: true}\n",
        "handle_base, pixels, FV_SIZE = module_selection\n",
        "MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/2\".format(handle_base)\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "print(\"Using {} with input size {} and output dimension {}\".format(\n",
        "  MODULE_HANDLE, IMAGE_SIZE, FV_SIZE))\n",
        "\n",
        "BATCH_SIZE = 64 #@param {type:\"integer\"}"
      ],
      "metadata": {
        "id": "8RI7ped3Xj-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B5_qqUX7M_qF"
      },
      "cell_type": "markdown",
      "source": [
        "# Image Data Augmentation"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "LduUQoOwM_qF"
      },
      "cell_type": "code",
      "source": [
        "# Inputs are suitably resized for the selected module. Dataset augmentation (i.e., random distortions of an image each time it is read) improves training, esp. when fine-tuning.\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split = 0.2)\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    shuffle=False,\n",
        "    seed=42,\n",
        "    color_mode=\"rgb\",\n",
        "    class_mode=\"categorical\",\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE)\n",
        "\n",
        "do_data_augmentation = True #@param {type:\"boolean\"}\n",
        "if do_data_augmentation:\n",
        "  train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "      rotation_range=40,\n",
        "      horizontal_flip=True,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      fill_mode='nearest' )\n",
        "else:\n",
        "  train_datagen = validation_generator\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    subset=\"training\",\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    color_mode=\"rgb\",\n",
        "    class_mode=\"categorical\",\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pm7a-6FOM_qF"
      },
      "cell_type": "markdown",
      "source": [
        "# Build Model"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "9yp7K0r7M_qG"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "feature_extractor = hub.KerasLayer(MODULE_HANDLE,\n",
        "                                   input_shape=IMAGE_SIZE+(3,),\n",
        "                                   output_shape=[FV_SIZE])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "dzF8ghyjM_qG"
      },
      "cell_type": "code",
      "source": [
        "do_fine_tuning = False #@param {type:\"boolean\"}\n",
        "if do_fine_tuning:\n",
        "  feature_extractor.trainable = True\n",
        "  # unfreeze some layers of base network for fine-tuning\n",
        "  for layer in base_model.layers[-30:]:\n",
        "    layer.trainable =True\n",
        "\n",
        "else:\n",
        "  feature_extractor.trainable = False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Xx4hn8HMM_qG"
      },
      "cell_type": "code",
      "source": [
        "print(\"Building model with\", MODULE_HANDLE)\n",
        "model = tf.keras.Sequential([\n",
        "    feature_extractor,\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    tf.keras.layers.Dense(train_generator.num_classes, activation='softmax',\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
        "])\n",
        "#model.build((None,)+IMAGE_SIZE+(3,))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zYxlkvn0M_qG"
      },
      "cell_type": "markdown",
      "source": [
        "# Specifying Loss Functions"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "b--oeRqxM_qG"
      },
      "cell_type": "code",
      "source": [
        "#Compile model specifying the optimizer learning rate\n",
        "\n",
        "LEARNING_RATE = 0.001 #@param {type:\"number\"}\n",
        "\n",
        "model.compile(\n",
        "   optimizer=tf.keras.optimizers.Adam(lr=LEARNING_RATE),\n",
        "   loss='categorical_crossentropy',\n",
        "   metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "l3qbQ3bGM_qG"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "EPOCHS=5 #@param {type:\"integer\"}\n",
        "\n",
        "history = model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=validation_generator.samples//validation_generator.batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.load(\"/content/my_model.h5\")"
      ],
      "metadata": {
        "id": "wPQnKS-aEkvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "_tbItfD6M_qG"
      },
      "cell_type": "code",
      "source": [
        "preds = model.predict_generator(validation_generator, steps=5)\n",
        "label = validation_generator.classes\n",
        "pred = model.predict(validation_generator)\n",
        "\n",
        "predicted_class_indices=np.argmax(pred,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "PiwYUB7PM_qG"
      },
      "cell_type": "code",
      "source": [
        "labels = (validation_generator.class_indices)\n",
        "labels2 = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels2[k] for k in predicted_class_indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "9BLnNvwvM_qG"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "cf_report = classification_report(predicted_class_indices,label)\n",
        "cm = confusion_matrix(predicted_class_indices,label)\n",
        "\n",
        "print(cf_report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "2ZLH5lyrM_qH"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "ax = sns.heatmap(cm, cmap=plt.cm.plasma, annot=True, square=True, xticklabels=disease_types, yticklabels=disease_types)\n",
        "\n",
        "ax.set_ylabel('Actual', fontsize=40)\n",
        "ax.set_xlabel('Predicted', fontsize=40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0CZjGbmyM_qH"
      },
      "cell_type": "markdown",
      "source": [
        "# Random Image testing"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "jPXmm0IwM_qH"
      },
      "cell_type": "code",
      "source": [
        "image_path = '../input/plantdisease/PlantVillage/Pepper__bell___Bacterial_spot/01613cd0-d3cd-4e96-945c-a312002037bf___JR_B.Spot 3262.JPG'\n",
        "image = tf.keras.preprocessing.image.load_img(image_path, target_size=(299, 299))\n",
        "input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
        "input_arr = np.expand_dims(input_arr, axis=0)\n",
        "input_arr = input_arr / 255.0  # Normalize the input image\n",
        "\n",
        "# Run inference\n",
        "output_probs = model.predict(input_arr)\n",
        "\n",
        "# Get predicted class index\n",
        "preds1 = np.argmax(output_probs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "zYf3jy7qM_qH"
      },
      "cell_type": "code",
      "source": [
        "preds1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fU0dYn-4M_qH"
      },
      "cell_type": "markdown",
      "source": [
        "# Converting to Tensorflow Lite and modelh5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/model_v2.h5\"\n",
        "tf.saved_model.save(model, path)"
      ],
      "metadata": {
        "id": "Zhc_p5gvgT5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cara Makai h5"
      ],
      "metadata": {
        "id": "J4wW7EO8i6qG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat kembali model dari TensorFlow SavedModel\n",
        "loaded_model = tf.saved_model.load(path)\n"
      ],
      "metadata": {
        "id": "kPIOsIbjg2zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = '../input/plantdisease/PlantVillage/Pepper__bell___Bacterial_spot/01613cd0-d3cd-4e96-945c-a312002037bf___JR_B.Spot 3262.JPG'\n",
        "image = tf.keras.preprocessing.image.load_img(image_path, target_size=(299, 299))\n",
        "input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
        "input_arr = np.expand_dims(input_arr, axis=0)\n",
        "input_arr = input_arr / 255.0  # Normalize the input image\n",
        "\n",
        "# Run inference\n",
        "output_probs = loaded_model(input_arr)\n",
        "\n",
        "# Get predicted class index\n",
        "preds1 = np.argmax(output_probs)\n",
        "print(preds1)"
      ],
      "metadata": {
        "id": "zhfjJ5Gtg72A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "from google.colab import files as colab_files\n",
        "\n",
        "# Path folder yang ingin Anda kompres\n",
        "folder_path = \"/content/model_v2.h5\"\n",
        "\n",
        "# Nama file zip yang akan dihasilkan\n",
        "zip_file_name = \"model-v1.zip\"\n",
        "\n",
        "# Kompres folder menjadi file zip\n",
        "with ZipFile(zip_file_name, 'w') as zipf:\n",
        "    for root, _, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), os.path.join(folder_path, '..')))\n",
        "\n",
        "# Unduh file zip\n",
        "colab_files.download(zip_file_name)\n"
      ],
      "metadata": {
        "id": "zCDchzg6hh3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "tWz7nYTyM_qH"
      },
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_float_model = converter.convert()\n",
        "\n",
        "# Show model size in KBs.\n",
        "float_model_size = len(tflite_float_model) / 1024\n",
        "print('Float model size = %dKBs.' % float_model_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "B8_j1Bh6M_qH"
      },
      "cell_type": "code",
      "source": [
        " # Re-convert the model to TF Lite using quantization.\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quantized_model = converter.convert()\n",
        "\n",
        "# Show model size in KBs.\n",
        "quantized_model_size = len(tflite_quantized_model) / 1024\n",
        "print('Quantized model size = %dKBs,' % quantized_model_size)\n",
        "print('which is about %d%% of the float model size.'\\\n",
        "      % (quantized_model_size * 100 / float_model_size))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "AdxTqoxyM_qI"
      },
      "cell_type": "code",
      "source": [
        "f = open('plant_model.tflite', \"wb\")\n",
        "f.write(tflite_quantized_model)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cara makai TFlite"
      ],
      "metadata": {
        "id": "2OEsx6Igi3VM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_model_path = \"/content/plant_model.tflite\"  # Ganti dengan path ke model TensorFlow Lite Anda\n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
        "interpreter.allocate_tensors()\n"
      ],
      "metadata": {
        "id": "VCgOC8W_d-uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = '/kaggle/input/plantdisease/PlantVillage/Pepper__bell___Bacterial_spot/0022d6b7-d47c-4ee2-ae9a-392a53f48647___JR_B.Spot 8964.JPG'\n",
        "image = tf.keras.preprocessing.image.load_img(image_path, target_size=(299, 299))\n",
        "input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
        "input_arr = np.expand_dims(input_arr, axis=0)\n",
        "input_arr = input_arr / 255.0  # Normalisasi gambar input\n"
      ],
      "metadata": {
        "id": "WFHABk3HeFbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_index = interpreter.get_input_details()[0]['index']\n",
        "interpreter.set_tensor(input_index, input_arr)\n"
      ],
      "metadata": {
        "id": "eutSSKwveHsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter.invoke()\n"
      ],
      "metadata": {
        "id": "CpipR6Z7eJTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\n",
        "    \"Pepper__bell___Bacterial_spot\", \"Pepper__bell___healthy\",\n",
        "    \"Tomato_Bacterial_spot\", \"Tomato_Early_blight\", \"Tomato_Late_blight\",\n",
        "    \"Tomato_Leaf_Mold\", \"Tomato_Septoria_leaf_spot\",\n",
        "    \"Tomato_Spider_mites_Two_spotted_spider_mite\", \"Tomato__Target_Spot\",\n",
        "    \"Tomato__Tomato_YellowLeaf__Curl_Virus\", \"Tomato__Tomato_mosaic_virus\",\n",
        "    \"Tomato_healthy\"\n",
        "]"
      ],
      "metadata": {
        "id": "2kA2PGmAe13Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_index = interpreter.get_output_details()[0]['index']\n",
        "output = interpreter.get_tensor(output_index)\n",
        "predicted_class_index = np.argmax(output)\n",
        "predicted_class_name = class_names[predicted_class_index]\n",
        "print(predicted_class_index)\n",
        "print(\"Predicted class:\", predicted_class_name)"
      ],
      "metadata": {
        "id": "b8E3_m85eKhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Tentukan path file yang ingin diunduh\n",
        "file_path = \"/content/plant_model.tflite\"\n",
        "\n",
        "# Unduh file\n",
        "files.download(file_path)"
      ],
      "metadata": {
        "id": "4TDmLVOAiVF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batas kesalahan"
      ],
      "metadata": {
        "id": "CFcMi5jod_MF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Memuat model dari file .h5\n",
        "loaded_model = load_model(\"/content/my_model.h5\",custom_objects={'KerasLayer':hub.KerasLayer}\n",
        ")"
      ],
      "metadata": {
        "id": "up69vCyx9l9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "0RMCZi-_M_qI"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# Load the pre-trained InceptionV3 model from TensorFlow Hub\n",
        "inception_v3 = tf.keras.Sequential([\n",
        "    hub.KerasLayer('https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/2', input_shape=(299, 299, 3))\n",
        "])\n",
        "\n",
        "# Load just the weights of the custom layers from plant_model.h5\n",
        "custom_model = tf.keras.models.load_model(\"/content/plant_model.h5\",custom_objects={'KerasLayer':hub.KerasLayer})\n",
        "custom_weights = custom_model.get_weights()\n",
        "\n",
        "# Set the weights of the custom layers in the InceptionV3 base model\n",
        "for layer in inception_v3.layers:\n",
        "    if layer.name.startswith('your_custom_layer_prefix'):  # Replace 'your_custom_layer_prefix' with the prefix used in your custom model\n",
        "        layer.set_weights(custom_weights)\n",
        "\n",
        "# Combine the InceptionV3 base model with the custom layers\n",
        "combined_model = tf.keras.Sequential([\n",
        "    inception_v3,\n",
        "    tf.keras.layers.Flatten(),  # Add a Flatten layer if needed\n",
        "    # Add more layers as needed\n",
        "])\n",
        "\n",
        "# Continue with the rest of your code for image preprocessing and inference\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload model"
      ],
      "metadata": {
        "id": "tUMqlOdymBWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "model_path = files.upload()"
      ],
      "metadata": {
        "id": "7hUxCZggmEAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Coba generate api\n"
      ],
      "metadata": {
        "id": "tTbuVkIzkjgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "pa50hErCleMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Python SDK\n",
        "import google.generativeai as genai\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "HyXTv1Px61Jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-pro')"
      ],
      "metadata": {
        "id": "GUZjtS8cku_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"Hello\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "wHDu--2Cl8Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementasi model dan gemini"
      ],
      "metadata": {
        "id": "hdQDUZYo2DVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(model_path, image_path):\n",
        "    # Load model\n",
        "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    # Load image and preprocess\n",
        "    image = tf.keras.preprocessing.image.load_img(image_path, target_size=(299, 299))\n",
        "    input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
        "    input_arr = np.expand_dims(input_arr, axis=0)\n",
        "    input_arr = input_arr / 255.0  # Normalize the input image\n",
        "\n",
        "    # Set input tensor\n",
        "    input_index = interpreter.get_input_details()[0]['index']\n",
        "    interpreter.set_tensor(input_index, input_arr)\n",
        "\n",
        "    # Invoke interpreter\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Get output tensor and predicted class\n",
        "    output_index = interpreter.get_output_details()[0]['index']\n",
        "    output = interpreter.get_tensor(output_index)\n",
        "    predicted_class_index = np.argmax(output)\n",
        "\n",
        "    class_names = [\n",
        "        \"Pepper_bell_Bacterial_spot\", \"Pepper_bell_healthy\",\n",
        "        \"Tomato_Bacterial_spot\", \"Tomato_Early_blight\", \"Tomato_Late_blight\",\n",
        "        \"Tomato_Leaf_Mold\", \"Tomato_Septoria_leaf_spot\",\n",
        "        \"Tomato_Spider_mites_Two_spotted_spider_mite\", \"Tomato_Target_Spot\",\n",
        "        \"Tomato_YellowLeaf_Curl_Virus\", \"Tomato_Tomato_mosaic_virus\",\n",
        "        \"Tomato_healthy\"\n",
        "    ]\n",
        "\n",
        "    predicted_class_name = class_names[predicted_class_index]\n",
        "\n",
        "    return predicted_class_name"
      ],
      "metadata": {
        "id": "ugs9Bbgeov_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt_disease(disease):\n",
        "    # Dapatkan kunci API Google Anda dari userdata\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "    # Konfigurasi kunci API\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "    # Buat instance model GenerativeModel untuk Gemini\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "    # Prompt berdasarkan penyakit\n",
        "    prompt = f\"Jelaskan Penyakit {disease}: Pengertian, Penyebab, dan Cara Penanganan singkat dalam 3 paragraf.\"\n",
        "\n",
        "    # Gunakan model untuk menghasilkan konten berdasarkan prompt\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    # Cetak hasil konten yang dihasilkan\n",
        "    return response.text\n"
      ],
      "metadata": {
        "id": "4100QhBJph-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    model_path = \"/content/plant_model.tflite\"\n",
        "    image_path = \"/content/TomatoYellowCurlVirus6.JPG\"\n",
        "    predicted_class = predict_image(model_path, image_path)\n",
        "    print(prompt_disease(predicted_class))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "yLIOPjKcp7Gt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}